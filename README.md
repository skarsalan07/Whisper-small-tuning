# Whisper Fine-Tuning for Technical Terms

## ðŸ“– Problem Statement
OpenAI's Whisper models (including Whisper Large v3 and Whisper Large v3 Turbo) often fail to recognize **technical terms** such as:
mvn , maven , github , git , portkey , openai , chatgpt , llm , groq , Grok


This project focuses on **fine-tuning Whisper** so that i,t correctly transcribes these terms in speech.

---

## ðŸš€ Approach
Due to resource and GPU limitations, this project fine-tunes **Whisper Small** instead of Whisper Large v3/v3 Turbo.  
The approach includes:
- Preparing a dataset with audio samples of technical terms.
- Fine-tuning Whisper Small on the dataset.
- Comparing transcription performance **before vs after fine-tuning**.

---

## ðŸ“‚ Folder Structure
```
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ audio/
â”‚ â”‚ â”œâ”€â”€ train/ # Training audio files
â”‚ â”‚ â””â”€â”€ test/ # Test audio files
â”‚ â””â”€â”€ transcripts/
â”‚ â”œâ”€â”€ train.jsonl # Training transcripts
â”‚ â””â”€â”€ test.jsonl # Test transcripts
â”‚
â”‚â”€â”€ Whisper_fine_tuning.ipynb # Training notebook
â”‚â”€â”€ finetuned-small/ # Saved fine-tuned model
â”‚â”€â”€ results/ # Baseline vs fine-tuned comparison
```
# Install dependencies
pip install transformers datasets jiwer torchaudio

ðŸ“Š Dataset Format
Each transcript file (train.jsonl, test.jsonl) contains JSON lines:
```
{"audio": "data/audio/train/sample1.mp3", "sentence": "github is a version control platform"}
{"audio": "data/audio/train/sample2.mp3", "sentence": "maven is used for build automation"}
```
